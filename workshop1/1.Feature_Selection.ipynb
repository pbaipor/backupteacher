{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.datasets import make_regression, load_boston\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import RFE, RFECV, f_regression\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, RandomizedLasso\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from minepy import MINE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important things in Machine Learning is the __statement of attributes__, which involves both the part of __selection of attributes__ (_feature selection_) and __creation of attributes__ (_feature creation_). In this notebook, we will focus on the selection of attributes.\n",
    "\n",
    "Most machine learning algorithms suffer from a problem: if you give them bad attributes, the result is likely to be bad as well. Bad attributes involve from inconsistent or wrong data to noise in the data. This is even more crucial when the number of attributes is very large. In general, you do not need to use all the attributes. In addition to reducing training time, fewer attributes also mean fewer problems to worry about. It's like that old diatado says: _\"Less is more!\"_\n",
    "\n",
    "The selection of attributes is important because:\n",
    "\n",
    "- leaves the __training faster__, shortening training time;\n",
    "- __reduces the complexity of a model__ and makes it simpler to interpret;\n",
    "- __facilitates the understanding of the relation of the attributes with the output__;\n",
    "- improves the accuracy of the model if the \"optimal\" subset is chosen; and\n",
    "- __reduces the chance of overfitting and improves generalization__\n",
    "\n",
    "We can group the attribute selection algorithms into 3 types: __filter methods__, __packaging methods__ (_wrapper methods_) and __carried methods__ (_embedded methods_). In the following sections, we'll look at the differences between them.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Methods\n",
    "<img src='images/select_filter_methods.png'>\n",
    "\n",
    "Filtering methods, also known as \"univariate attribute selection\" (_univariate feature selection_), are generally used as pre-processing. The selection of attributes is independent of any machine learning algorithm. Instead, each attribute is examined individually to determine the strength of its relationship to the variable response (output). These methods are simple to run, understand, and are generally good at getting a good understanding of data (but not necessarily optimizing the set of attributes for better generalization). There are a lot of filtering methods. As a basic guide, you can consider the following table that defines some of the univariate selection methods:\n",
    "\n",
    "| Atributo\\Resposta |        Continuous       | Category            |\n",
    "|:-----------------:|:---------------------:|:---------------------:|\n",
    "|   __Continuous__    | Pearson's Correlation | LDA                   |\n",
    "|  __Category__   |         ANOVA         | Chi-Square ($\\chi^2$) |\n",
    "\n",
    "\n",
    "- __Pearson's correlation__: used to quantify the linear correlation between two continuous variables $X$ and $Y$. The output varies from $[- 1, +1]$, where $ -1 $ means perfect negative correlation (when $ X $ grows, $ Y $ decreases) and $ + 1 $ means perfect positive correlation (when $ X $ grows , $ Y $ grows). The Pearson correlation coefficient $ P (X, Y) $ is given by:\n",
    "\n",
    "$$ P(X,Y) = \\frac{cov(X, Y)}{\\sigma_X \\sigma_Y} $$\n",
    "\n",
    "- __LDA__: stands for Linear Discriminant Analysis (_linear discriminant analysis_) and is used to find the best linear combination of attributes that separate two or more classes. You can check out a full notebook on LDA in this same repository by clicking [here] (LDA.ipynb).\n",
    "- __ANOVA__: statistical test that means __analysis of variance__. It is similar to LDA, but functions for one or more independent categorical attributes and a continuous attribute as output. This test indicates whether the average of several groups are equal or not.\n",
    "- __Chi-square ($\\chi^2$) __: is also a statistical test, only applied to groups of categorical attributes to evaluate the probability of correlation or association between them using their frequency distributions.\n",
    "\n",
    "One thing to keep in mind is that filtering methods do NOT remove multicollinearity. Therefore, you should also be concerned with the multicollinearity of attributes before you train your model.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson's Correlation\n",
    "__One disadvantage of Pearson's correlation coefficient is that it is sensitive only to linear relations.__ If the relationship is nonlinear, the Pearson correlation can be close to zero even if there is a 1: 1 match between the two variables. For example, the correlation between $x$ and $x^2$ is approximately 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.05214981]\n",
      " [ 0.05214981  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.uniform(-1, 1, 1000)\n",
    "print(np.corrcoef(x.T, x**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check some examples of the Pearson coefficient for some data types:\n",
    "\n",
    "<img src='images/selecao_pearson.png'>\n",
    "\n",
    "In addition, we can see, in the figure below, different data that has the same number of points and the same Pearson correlation coefficient, but totally different graphs. So it's always worth plotting the data, if possible:\n",
    "\n",
    "<img src='images/selecao_pearson_plots.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Information\n",
    "A more robust option to the Pearson coefficient is the __mutual information (MI) __, which measures the mutual dependence between variables, usually in bits. Mutual information is defined as:\n",
    "\n",
    "$$I(X, Y) = \\sum_{y\\in Y} \\sum_{x \\in X} p(x, y)log \\left(\\frac{p(x,y)}{p(x)p(y)}\\right)$$\n",
    "\n",
    "However, it can be inconvenient when used directly for attribute ranking for two reasons:\n",
    "\n",
    "1. __It is not a metric and is not normalized__. Therefore, IM values can not be compared between two datasets.\n",
    "2. __It is not suitable for continuous variables__. In general, the variables need to be discretized for the construction of the bins, however the information of the score can be very sensitive the selection of the bins.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximal Information Coefficient\n",
    "__Maximal Information Coefficient (MIC) __ is a technique developed to address the deficiencies of _mutual information_. It looks for optimal bins and still normalizes the _mutual information_ score between $[0, 1]$. In python, it can be implemented using the __minepy__ library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "x = np.random.uniform(-1, 1, 1000)\n",
    "\n",
    "m = MINE()\n",
    "m.compute_score(x, x**2)\n",
    "print(m.mic())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there are some criticisms ([here](http://ie.technion.ac.il/~gorfinm/files/science6.pdf) e [here](http://www-stat.stanford.edu/~tibs/reshef/comment.pdf)) regarding the statistical power of the MIC, that is, the ability to reject the null hypothesis when it is false. This may or may not be a problem, depending on the bank and its noise.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper Methods\n",
    "<img src='images/selecao_wrapper_methods.png' width=\"700\">\n",
    "\n",
    "Packaging methods try to use a subset of attributes and train a model with this subset. __ Based on the result of the previous model, the algorithm decides to add or remove attributes from the subset__. This problem is essentially reduced to a search problem. __The packaging methods are usually very computationally expensive__.\n",
    "\n",
    "The most common packaging algorithms are divided into 3 groups:\n",
    "\n",
    "- __Forward Selection__: iterative method in which the algorithm starts without any attribute in the model. At each iteration, the algorithm adds the attribute that provides the highest performance gain. The algorithm ends when adding new attributes does not improve algorithm performance.\n",
    "- __Backward Elimination__: In this method, the algorithm starts with all attributes and, at each iteration, removes the attribute with the least significance or, when removed, improves the performance of the model. This procedure is repeated until no improvement is observed in the removal of the attributes.\n",
    "- __Recursive Feature Elimination__: is a greedy optimization algorithm whose goal is to find the best subset of attributes. Repeatedly, the algorithm creates models and holds the best or worst attribute at each iteration. So a new model is trained with the best attributes until the attributes run out. Finally, the algorithm makes the ranking of attributes based on the order of their deletions.\n",
    "\n",
    "Below, we'll look at some of the most commonly used packaging methods\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stability Selection\n",
    "[Stability selection](http://stat.ethz.ch/~nicolai/stability.pdf) is considered a relatively new attribute selection method, based on the subsampling and combination of selection algorithms (which can be regressors, SVMs or other similar methods). __The main idea is to apply an attribute selector algorithm in different subsets of the data and with different subset of the attributes__. After repeating this process a number of times, the selection results can be aggregated, for example, by counting how many times an attribute was selected as important when it was in a subset of attributes. It is expected that important attributes score close to 100%, since they should always be selected when possible. Weak attributes, but still relevant, will have non-zero scores, since they were selected when important attributes were not present in the current selected subset. Unreliable attributes, in turn, should have scores (close to) zero, since they should not be present in the selected attributes.\n",
    "\n",
    "Sklearn implements stability selection in the [randomized lasso](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RandomizedLasso.html) e [randomized logistic regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RandomizedLogisticRegression.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "x = boston['data']\n",
    "y = boston['target']\n",
    "names = boston['feature_names']\n",
    "\n",
    "rlasso = RandomizedLasso(alpha=0.025, random_state=42)\n",
    "rlasso.fit(x, y)\n",
    "\n",
    "print(\"Atributos ordenados pelo score:\")\n",
    "print(sorted(zip(rlasso.scores_, names), reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the 3 most important attributes have a score equal to 1.0, that is, they have always been chosen as useful attributes. Obviously, this result may be different for other throttling parameters, even though the implementation of sklearn is able to choose a good $ \\ alpha $ automatically. The rest of the scores decrease dramatically after these 3 attributes, however the attributes are usually not as aggressive as in the case of pure Lasso or Random Forest. __This means that the stability selected is useful both in pure attribute selection to reduce overfitting and in data interpretation__. In general, good attributes will have 0 as a coefficient just because they are similar or correlated in the dataset (as in the Lasso regression). __For selection of attributes, stability selection is among the best algorithms tested in different databases and configurations__.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive deletion of attributes\n",
    "__Recursive feature elimination, RFE__ is based on the idea of repeatedly constructing a model (eg SVM or regressor)__and choosing the best or worst attribute__ (for example, based on the coefficients), __ separating this attribute and repeating the process with the others__. This process is applied until all the attributes in the dataset have been used. __The attributes are then ranked according to the order of elimination__. Therefore, this represents a greedy optimization process to find the best subset of attributes.\n",
    "\n",
    "__The stability of the RFE is quite dependent on the type of model used for attribute ranking in each iteration__.\n",
    "\n",
    "Sklearn provides the [RFE](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html) for recursive attribute deletion and [RFECV](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html) to find the rankings and optimal quantity of attributes via cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes sorted rank:\n",
      "[(1, 'NOX'), (2, 'RM'), (3, 'CHAS'), (4, 'PTRATIO'), (5, 'DIS'), (6, 'LSTAT'), (7, 'RAD'), (8, 'CRIM'), (9, 'INDUS'), (10, 'ZN'), (11, 'TAX'), (12, 'B'), (13, 'AGE')]\n"
     ]
    }
   ],
   "source": [
    "boston = load_boston()\n",
    "x = boston['data']\n",
    "y = boston['target']\n",
    "names = boston['feature_names']\n",
    "\n",
    "# uses linear regression as a model\n",
    "lr = LinearRegression()\n",
    "rfe = RFE(estimator=lr, n_features_to_select=1)\n",
    "rfe.fit(x, y)\n",
    "\n",
    "print(\"Attributes sorted rank:\")\n",
    "print(sorted(zip(rfe.ranking_, names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes sorted rank:\n",
      "[(1, 'CHAS'), (1, 'DIS'), (1, 'LSTAT'), (1, 'NOX'), (1, 'PTRATIO'), (1, 'RM'), (2, 'RAD'), (3, 'CRIM'), (4, 'INDUS'), (5, 'ZN'), (6, 'TAX'), (7, 'B'), (8, 'AGE')]\n"
     ]
    }
   ],
   "source": [
    "boston = load_boston()\n",
    "x = boston['data']\n",
    "y = boston['target']\n",
    "names = boston['feature_names']\n",
    "\n",
    "# uses linear regression as a model\n",
    "lr = LinearRegression()\n",
    "rfe = RFECV(estimator=lr, step=1, cv=10, n_jobs=-1)\n",
    "rfe.fit(x, y)\n",
    "\n",
    "print(\"Attributes sorted rank:\")\n",
    "print(sorted(zip(rfe.ranking_, names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.76405235  0.40015721  0.97873798]\n",
      " [ 2.2408932   1.86755799 -0.97727788]\n",
      " [ 0.95008842 -0.15135721 -0.10321885]\n",
      " ..., \n",
      " [ 1.91662273 -1.24813317  0.12762022]\n",
      " [ 1.20272166  0.62844209  1.83888091]\n",
      " [ 0.75309415 -0.58103281 -0.19837974]]\n",
      "[ 7.50433081  7.15004266 -0.14733131 ..., -0.69416212  0.34174332\n",
      " -1.06202835]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.98422873,  1.99522378, -0.04074316])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "x = np.random.normal(0, 1, (5000, 3))\n",
    "y = x[:, 0] + 2*x[:, 1] + np.random.normal(0, 2, 5000)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(x, y)\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.057850509972938058"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in this example, the model certainly recovers the fundamental structure of the data very well, despite the significant noise we place in the data. __Repare how the coefficient of $x_2$ is practically double $ x_1 $, and how the noise coefficient ($ x_3 $ is practically zero) __. In fact, this problem is particularly simple for a linear model: __ purely linear relationship between attributes and variable response and no correlation between attributes.\n",
    "\n",
    "When there are multiple (linearly) correlated attributes - as is the case with many real-world data - the model becomes unstable, ie small changes in data can cause large changes in model coefficients, making model interpretation very difficult , also called the \"multicollinearity problem\".\n",
    "\n",
    "Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.2912413   1.59097473  2.74727029]\n"
     ]
    }
   ],
   "source": [
    "size = 100\n",
    "np.random.seed(5)\n",
    "\n",
    "x_seed = np.random.normal(0, 1, size)\n",
    "x1 = x_seed + np.random.normal(0, 0.1, size)\n",
    "x2 = x_seed + np.random.normal(0, 0.1, size)\n",
    "x3 = x_seed + np.random.normal(0, 0.1, size)\n",
    "\n",
    "y = x1 + x2 + x3 + np.random.normal(0, 1, size)\n",
    "x = np.array([x1, x2, x3]).T\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(x, y)\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Regularization is a method to add restrictions or penalties to a model with the objective of preventing overfitting and improving generalization__. Instead of minimizing the cost function $ E (x, y) $, the cost function becomes $ E (x, y) + \\ alpha \\ | w \\ | $, where $ w $ is the coefficient vector of the model, $ \\ | \\ cdot \\ | $ is typically the norm L1 or L2 and $ \\ alpha $ is a tunable parameter that specifies the force of regularization ($ \\ alpha = 0 $ means \"without regularization\"). In relation to linear models, the two most used regularization methods are L1 and L2, also known as [Lasso](http://en.wikipedia.org/wiki/Least_squares#Lasso_method) and [Ridge](http://en.wikipedia.org/wiki/Tikhonov_regularization), respectively, when applied in linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 regularization / Lasso\n",
    "\n",
    "L1 regularization adds a penalty $\\alpha \\sum_{i=1}^n \\left|w_i\\right|$ to the loss function (L1-norm). Since each non-zero coefficient adds to the penalty, it forces weak features to have zero as coefficients. Thus L1 regularization produces sparse solutions, inherently performing feature selection.\n",
    "For regression, Scikit-learn offers [Lasso](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) for [Logistic regression ](http://blog.datadive.net/selecting-good-features-part-ii-linear-models-and-regularization/scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)and Logistic regression with L1 penalty for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIM: -0.242\n",
      "ZN: 0.082\n",
      "INDUS: -0.0\n",
      "CHAS: 0.54\n",
      "NOX: -0.699\n",
      "RM: 2.993\n",
      "AGE: -0.0\n",
      "DIS: -1.081\n",
      "RAD: 0.0\n",
      "TAX: -0.0\n",
      "PTRATIO: -1.756\n",
      "B: 0.628\n",
      "LSTAT: -3.705\n"
     ]
    }
   ],
   "source": [
    "boston = load_boston()\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(boston['data'])\n",
    "y = boston['target']\n",
    "names = boston['feature_names']\n",
    "\n",
    "lasso = Lasso(alpha=0.3, random_state=42)\n",
    "lasso.fit(x, y)\n",
    "\n",
    "for c, att in zip(lasso.coef_, names):\n",
    "    print('{}: {}'.format(att, round(c, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that a number of features have coefficient 0. If we increase α further, the solution would be sparser and sparser, i.e. more and more features would have 0 as coefficients.\n",
    "\n",
    "Note however that L1 regularized regression is unstable in a similar way as unregularized linear models are, meaning that the coefficients (and thus feature ranks) can vary significantly even on small data changes when there are correlated features in the data. Which brings us to L2 regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 regularization / Ridge\n",
    "L2 regularization (called ridge regression for linear regression) adds the [L2 norm](http://en.wikipedia.org/wiki/Norm_%28mathematics%29#Euclidean_norm)penalty ($\\alpha\\sum_{i=1}^n w_i^2$) to the loss function.\n",
    "\n",
    "Since the coefficients are squared in the penalty expression, it has a different effect from L1-norm, namely it forces the coefficient values to be spread out more equally. For correlated features, it means that they tend to get similar coefficients. Coming back to the example of $y = x_1 + x_2$, with strongly correlated $X_1$ and $X_2$, then for L1, the penalty is the same whether the learned model is $y = 1*x_1 + 1*x_2$ or $y = 2*x_1 + 0*x_2$. In both cases the penalty is $2\\alpha$. For L2 however, the first model’s penalty is $1^2 + 1^2 = 2\\alpha$, while for the second model is penalized with $2^2 + 0^2 = 4\\alpha$.\n",
    "\n",
    "The effect of this is that models are much more stable (coefficients do not fluctuate on small data changes as is the case with unregularized or L1 models). So while L2 regularization does not perform feature selection the same way as L1 does, it is more useful for feature *interpretation*: a predictive feature will get a non-zero coefficient, which is often not the case with L1.\n",
    "\n",
    "Lets look at the example with three correlated features again, running the example 10 times with different random seeds, to emphasize the stability of L2 regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed: 0\n",
      "Linear model: [ 0.7284403   2.30926001 -0.08219169]\n",
      "Ridge model: [ 0.93832131  1.05887277  0.87652644]\n",
      "\n",
      "Random seed: 1\n",
      "Linear model: [ 1.15181561  2.36579916 -0.59900864]\n",
      "Ridge model: [ 0.98409577  1.06792673  0.75855367]\n",
      "\n",
      "Random seed: 2\n",
      "Linear model: [ 0.69734749  0.32155864  2.08590886]\n",
      "Ridge model: [ 0.97159124  0.94256202  1.08539406]\n",
      "\n",
      "Random seed: 3\n",
      "Linear model: [ 0.28735446  1.25386129  1.49054726]\n",
      "Ridge model: [ 0.91891806  1.00474386  1.03276594]\n",
      "\n",
      "Random seed: 4\n",
      "Linear model: [ 0.18726691  0.77214206  2.1894915 ]\n",
      "Ridge model: [ 0.96401621  0.98152524  1.0983599 ]\n",
      "\n",
      "Random seed: 5\n",
      "Linear model: [-1.2912413   1.59097473  2.74727029]\n",
      "Ridge model: [ 0.75819864  1.01085804  1.1390417 ]\n",
      "\n",
      "Random seed: 6\n",
      "Linear model: [ 1.19909595 -0.0306915   1.91454912]\n",
      "Ridge model: [ 1.01616507  0.89032238  1.0907386 ]\n",
      "\n",
      "Random seed: 7\n",
      "Linear model: [ 1.47386769  1.76236014 -0.15057274]\n",
      "Ridge model: [ 1.0179376   1.03865514  0.90082373]\n",
      "\n",
      "Random seed: 8\n",
      "Linear model: [ 0.0840547   1.87985845  1.10688887]\n",
      "Ridge model: [ 0.90685834  1.07119752  1.00837994]\n",
      "\n",
      "Random seed: 9\n",
      "Linear model: [ 0.71408648  0.77601368  1.36406398]\n",
      "Ridge model: [ 0.89617178  0.90340866  0.98015958]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "size = 100\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Random seed:\", i)\n",
    "    np.random.seed(seed=i)\n",
    "    x_seed = np.random.normal(0, 1, size)\n",
    "    x1 = x_seed + np.random.normal(0, 0.1, size)\n",
    "    x2 = x_seed + np.random.normal(0, 0.1, size)    \n",
    "    x3 = x_seed + np.random.normal(0, 0.1, size)    \n",
    "    y = x1 + x2 + x3 + np.random.normal(0, 1, size)\n",
    "    x = np.array([x1, x2, x3]).T\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x, y)\n",
    "    print(\"Linear model:\", lr.coef_)\n",
    "    \n",
    "    ridge = Ridge(alpha=10)\n",
    "    ridge = ridge.fit(x, y)\n",
    "    print(\"Ridge model:\", ridge.coef_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the example, the coefficients can vary widely for linear regression, depending on the generated data. For L2 regularized model however, the coefficients are quite stable and closely reflect how the data was generated (all coefficients close to 1).\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical example\n",
    "\n",
    "To finalize this notebook, we will apply most of the attribute selection methods we have seen to compare them. The dataset we are going to use is called __Friedman \\ # 1 regression dataset__ ([source](ftp://ftp.uic.edu/pub/depts/econ/hhstokes/e538/Friedman_mars_1991.pdf)). The data are generated according to the following formula:\n",
    "\n",
    "$$y = 10sin(\\pi x_1 x_2) + 20(x_3 – 0.5)^2 + 10x_4 + 5x_5 +\\epsilon$$\n",
    "\n",
    "where $x_1$ a $x_5$ are sampled from a uniform distribution and $\\epsilon$ is a noise with normal distribution $N(0,1)$. In addition, the original dataset has five noise attributes $x_6, \\dots, x_{10}$ independent of the response variable. We will increase the number of attributes with more 4 variables $x_{11}, \\dots, x_{14}$ which are strongly correlated with $x_1,\\dots,x_4$ respectively generated by:\n",
    "\n",
    "$$f(x) = x + N(0, 0.01)$$\n",
    "\n",
    "This produces a correlation coefficient greater than $0.999$ between the variables. Our objective with this example is to show how different ranking methods deal with correlations in data.\n",
    "\n",
    "We will also normalize the ranking scores to be between 0 (for the least important attribute) and 1 (for the most important attribute). In the case of the recursive elimination of attributes, the 5 most important attributes will receive score 1, and the rest of the attributes will have the score normalized between 0 and 1 according to their position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lin. Reg.</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>Stability</th>\n",
       "      <th>RFE</th>\n",
       "      <th>Corr.</th>\n",
       "      <th>MIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>0.57</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x5</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x6</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x7</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x8</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x9</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x10</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x11</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x12</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x13</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x14</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Lin. Reg.  Ridge  Lasso  Stability   RFE  Corr.   MIC\n",
       "x1        1.00   0.77   0.79       0.77  1.00   0.30  0.39\n",
       "x2        0.56   0.75   0.83       0.73  1.00   0.44  0.61\n",
       "x3        0.50   0.05   0.00       0.00  1.00   0.00  0.34\n",
       "x4        0.57   1.00   1.00       1.00  1.00   1.00  1.00\n",
       "x5        0.27   0.88   0.51       0.64  0.78   0.10  0.20\n",
       "x6        0.02   0.05   0.00       0.00  0.44   0.00  0.00\n",
       "x7        0.00   0.01   0.00       0.00  0.00   0.01  0.07\n",
       "x8        0.03   0.09   0.00       0.00  0.56   0.02  0.05\n",
       "x9        0.00   0.00   0.00       0.00  0.11   0.01  0.09\n",
       "x10       0.01   0.01   0.00       0.00  0.33   0.00  0.04\n",
       "x11       0.60   0.59   0.00       0.36  1.00   0.29  0.43\n",
       "x12       0.14   0.68   0.00       0.55  0.67   0.44  0.71\n",
       "x13       0.48   0.02   0.00       0.00  0.89   0.00  0.23\n",
       "x14       0.00   0.95   0.16       0.69  0.22   0.99  1.00"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "\n",
    "size = 750\n",
    "x = np.random.uniform(0, 1, (size, 14))\n",
    "y = (10 * np.sin(np.pi*x[:,0]*x[:,1]) + 20*(x[:,2] - .5)**2 + 10*x[:,3] + 5*x[:,4] + np.random.normal(0,1))\n",
    "\n",
    "# adiciona 3 variáveis correlacionados com x1-x3\n",
    "x[:,10:] = x[:,:4] + np.random.normal(0, .025, (size,4))\n",
    " \n",
    "names = [\"x%s\" % i for i in range(1,15)] \n",
    "ranks = {}\n",
    "\n",
    "def rank_to_dict(ranks, names, order=1):\n",
    "    minmax = MinMaxScaler()\n",
    "    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n",
    "    ranks = [round(x, 2) for x in ranks]\n",
    "    return ranks\n",
    "\n",
    "lr = LinearRegression(normalize=True)\n",
    "lr.fit(x, y)\n",
    "ranks[\"Lin. Reg.\"] = rank_to_dict(np.abs(lr.coef_), names)\n",
    " \n",
    "ridge = Ridge(alpha=7)\n",
    "ridge.fit(x, y)\n",
    "ranks[\"Ridge\"] = rank_to_dict(np.abs(ridge.coef_), names)\n",
    " \n",
    "lasso = Lasso(alpha=.05)\n",
    "lasso.fit(x, y)\n",
    "ranks[\"Lasso\"] = rank_to_dict(np.abs(lasso.coef_), names)\n",
    " \n",
    "rlasso = RandomizedLasso(alpha=0.04, random_state=seed)\n",
    "rlasso.fit(x, y)\n",
    "ranks[\"Stability\"] = rank_to_dict(np.abs(rlasso.scores_), names)\n",
    " \n",
    "rfe = RFE(lr, n_features_to_select=5)\n",
    "rfe.fit(x, y)\n",
    "ranks[\"RFE\"] = rank_to_dict(list(map(float, rfe.ranking_)), names, order=-1)\n",
    " \n",
    "f, pval  = f_regression(x, y, center=True)\n",
    "ranks[\"Corr.\"] = rank_to_dict(f, names)\n",
    " \n",
    "mine = MINE()\n",
    "mic_scores = []\n",
    "for i in range(x.shape[1]):\n",
    "    mine.compute_score(x[:,i], y)\n",
    "    m = mine.mic()\n",
    "    mic_scores.append(m)\n",
    "\n",
    "ranks[\"MIC\"] = rank_to_dict(mic_scores, names)\n",
    "\n",
    "df = pd.DataFrame.from_dict(ranks)\n",
    "df = df.rename(index = dict(zip(range(14), names)))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above have some interesting features:\n",
    "- __Linear Regression__: As each attribute is evaluated independently, the scores for the attributes $x_1,\\dots,x_4$ are very similar to $x_{11},\\dots,x_14$, while the noise attributes $x_5,\\dots,x10$ are correctly identified to have almost no relation to the response variable. It is not possible to identify any relationship between $x_3$ and $y$, since this relationship is quadratic (in fact, this applies to almost all methods except the MIC). It is also possible to observe that while the method is able to measure the linear relationship between each attribute and the response variable, it is not optimal to select the best attributes to improve the generalization of the model, since the most important attributes will be essentially chosen twice .\n",
    "- __Lasso__: this method was able to select the best attributes, whereas other attributes to be close to zero. It is clearly useful when the intention is to reduce the number of attributes, but not necessarily to interpret the data (since it makes us believe that the attributes $x_{11},\\dots, x_ {13}$ does not have a strong relation with the response variable).\n",
    "- __MIC__: is similar to the correlation coefficient in relation to treating all attributes \"equally\". In addition, this method is able to find the nonlinear relationship between $x_3$ and the response variable.\n",
    "- __Ridge Regression__: This method forces the regression coefficients to similarly spread among the correlated variables. This is clearly visible in the example where $x_{11},\\dots,x_14$ are close to $x_1,\\dots,x_4$ in terms of scores.\n",
    "- __Stability Selection__: is generally able to make a good compromise between data interpretation and selection of better attributes for model improvement. This is well illustrated in the example. Like Lasso, this method is able to identify the best attributes ($x_1,x_2,x_4,x_5$). Likewise, the correlated variables $x_11,x12$ and $x14$ also have a high score, showing their relationship to the response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Attribute selection can be incredibly useful in a wide range of machine learning and data mining applications. __It is important to keep in mind why you are making attribute selection and understand which method works best for this purpose__. When selecting the best attributes to improve model performance, it is easy to verify that a particular method works well relative to other alternatives simply by performing cross-validation. However, it is not so simple when we use rankings to interpret the data, where the stability of the ranking method is crucial, and if the method does not have this property (like the Lasso regression), we can easily draw incorrect conclusions. What can be done is to sub-sample the data and run selection algorithms on the subsets. If the results are consistent on the subsets, it is relatively safe to rely on the stability of the method in that particular data and therefore easy to interpret the data in terms of rank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referance\n",
    "- [Feature Selection - Wikipedia](https://en.wikipedia.org/wiki/Feature_selection)\n",
    "- [Selecting good features – Part I: univariate selection](http://blog.datadive.net/selecting-good-features-part-i-univariate-selection/)\n",
    "- [Selecting good features – Part II: linear models and regularization](http://blog.datadive.net/selecting-good-features-part-ii-linear-models-and-regularization/)\n",
    "- [Selecting good features – Part IV: stability selection, RFE and everything side by side](http://blog.datadive.net/selecting-good-features-part-iv-stability-selection-rfe-and-everything-side-by-side/)\n",
    "- [Introduction to Feature Selection methods with an example (or how to select the right variables?)](https://www.analyticsvidhya.com/blog/2016/12/introduction-to-feature-selection-methods-with-an-example-or-how-to-select-the-right-variables/)\n",
    "- [BorutaPy](http://danielhomola.com/2015/05/08/borutapy-an-all-relevant-feature-selection-method/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
